{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Word Vectorization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQxIzRvx2BqjwjrL1+ymW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varmagsr/NLPVectorizationTechniques/blob/main/NLP_Word_Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install sklearn**"
      ],
      "metadata": {
        "id": "OD_TqhFZjcqb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9z4ZyHpd7mF",
        "outputId": "7e304873-21ce-47b6-a880-0a4efb095bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=6365a3288d6c992cbac16c6a59897e34cb3c57ed807f087c04909c3c19f9be32\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of *words*"
      ],
      "metadata": {
        "id": "OrgYK6AUjixU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sents = ['coronavirus is a highly infectious disease',\n",
        "   'coronavirus affects older people the most', \n",
        "   'older people are at high risk due to this disease']\n",
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "X = cv.fit_transform(sents) \n",
        "X = X.toarray()\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzBLng0Tjbho",
        "outputId": "cf69f872-a83b-49d6-95d7-bbca641b88c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0]\n",
            " [0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(cv.vocabulary_.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBHhdnlpk7ik",
        "outputId": "4fe0adb5-a35d-4059-e543-e7fec3146ebf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['affects older',\n",
              " 'are at',\n",
              " 'at high',\n",
              " 'coronavirus affects',\n",
              " 'coronavirus is',\n",
              " 'due to',\n",
              " 'high risk',\n",
              " 'highly infectious',\n",
              " 'infectious disease',\n",
              " 'is highly',\n",
              " 'older people',\n",
              " 'people are',\n",
              " 'people the',\n",
              " 'risk due',\n",
              " 'the most',\n",
              " 'this disease',\n",
              " 'to this']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF(Term Frequencyâ€“Inverse Document Frequency):\n"
      ],
      "metadata": {
        "id": "SJINlkB-phNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "sents = ['coronavirus is a highly infectious disease',\n",
        "   'coronavirus affects older people the most', \n",
        "   'older people are at high risk due to this disease']\n",
        "tfidf = TfidfVectorizer()\n",
        "transformed = tfidf.fit_transform(sents)\n"
      ],
      "metadata": {
        "id": "9SVzU0iRp4rN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(transformed[0].T.todense(),\n",
        "    \tindex=tfidf.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm4QEdbtxHqn",
        "outputId": "0116b6e9-1223-4b7d-ea76-6bb758bd6334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               TF-IDF\n",
            "infectious   0.490479\n",
            "highly       0.490479\n",
            "is           0.490479\n",
            "coronavirus  0.373022\n",
            "disease      0.373022\n",
            "older        0.000000\n",
            "this         0.000000\n",
            "the          0.000000\n",
            "risk         0.000000\n",
            "people       0.000000\n",
            "affects      0.000000\n",
            "most         0.000000\n",
            "are          0.000000\n",
            "high         0.000000\n",
            "due          0.000000\n",
            "at           0.000000\n",
            "to           0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n",
        "1. Skip-Gram"
      ],
      "metadata": {
        "id": "XDUvlQSUErCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n"
      ],
      "metadata": {
        "id": "Lj6OvHB7FcyV"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}